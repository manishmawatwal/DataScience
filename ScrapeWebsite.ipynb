{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScrapeWebsite.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYAJ0/AiJHTZtYQq/0zDc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manishmawatwal/DataScience/blob/main/ScrapeWebsite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAD_oQJMXQnI"
      },
      "source": [
        "#Description: Scrape Inspirational Quotes using Python"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XLGygnAYBTH"
      },
      "source": [
        "#importing libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib.request"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8sVQfukYPNt"
      },
      "source": [
        "#create lists to store scraped data\n",
        "authors = []\n",
        "quotes = []"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXcPxqYXaOq_"
      },
      "source": [
        "#create a function to scrape the website\n",
        "def scrape_website(page_number):\n",
        "  page_num = str(page_number)\n",
        "  url = 'https://www.goodreads.com/quotes/tag/inspirational?page='+ page_num\n",
        "  webpage = requests.get(url)\n",
        "  soup = BeautifulSoup(webpage.text, 'html.parser')\n",
        "  quoteText = soup.find_all('div', attrs = {'class':'quoteText'})\n",
        "\n",
        "  for i in quote_text:\n",
        "    quote = i.text.strip().split('\\n')[0]\n",
        "    author = i.find('span', attrs = {'class':'authorOrTitle'}).text.strip()\n",
        "    quotes.append(quote)\n",
        "    authors.append(author)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1kyK-aSuMEk"
      },
      "source": [
        "#scrape the website till n page numbers\n",
        "n = 10\n",
        "for i in range (0, n):\n",
        "  scrape_website(1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZe-xPFuPsW"
      },
      "source": [
        "#combine quotes lists and authors list\n",
        "combine_list = []\n",
        "for i in range(len(quotes)):\n",
        "  combine_list.append(quotes[i]+'-'+authors[i])\n",
        "combine_list"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}